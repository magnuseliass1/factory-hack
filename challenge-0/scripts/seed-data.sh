#!/bin/bash
set -e

# Load environment variables from .env in parent directory (root)
if [ -f ../.env ]; then
    set -a
    source ../.env
    set +a
    echo "âœ… Loaded environment variables from .env"
else
    echo "âŒ .env file not found in parent directory. Please run get-keys.sh first."
    exit 1
fi

echo "ðŸš€ Starting data seeding..."

# Install required Python packages
echo "ðŸ“¦ Installing required Python packages..."
pip3 install azure-cosmos --quiet
pip3 install azure-storage-blob --quiet

# Create Python script to handle the data import
cat > seed_data.py << 'EOF'
import json
import os
from azure.cosmos import CosmosClient, PartitionKey

def load_json_data(file_path):
    """Load data from JSON file"""
    data = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = json.load(f)
            # If it's already a list, use it as is
            if isinstance(content, list):
                data = content
            else:
                data = [content]
        print(f"âœ… Loaded {len(data)} records from {file_path}")
        return data
    except Exception as e:
        print(f"âŒ Error loading {file_path}: {e}")
        return []

def setup_cosmos_db():
    """Set up Cosmos DB database and containers"""
    print("ðŸ“¦ Setting up Cosmos DB...")
    
    # Initialize Cosmos client
    cosmos_client = CosmosClient(os.environ['COSMOS_ENDPOINT'], os.environ['COSMOS_KEY'])
    
    # Create database
    database_name = "FactoryOpsDB"
    try:
        database = cosmos_client.create_database_if_not_exists(id=database_name)
        print(f"âœ… Database '{database_name}' ready")
    except Exception as e:
        print(f"âŒ Error creating database: {e}")
        return None, None
    
    # Container definitions with partition keys and optional TTL
    containers_config = {
        'Machines': {'partition_key': '/type'},
        'Thresholds': {'partition_key': '/machineType'},
        'Telemetry': {'partition_key': '/machineId', 'ttl': 2592000},  # 30 days TTL
        'KnowledgeBase': {'partition_key': '/machineType'},
        'PartsInventory': {'partition_key': '/category'},
        'Technicians': {'partition_key': '/department'},
        'WorkOrders': {'partition_key': '/status'},
        'MaintenanceHistory': {'partition_key': '/machineId'},
        'MaintenanceWindows': {'partition_key': '/isAvailable'}
    }
    
    container_clients = {}
    for container_name, config in containers_config.items():
        try:
            container = database.create_container_if_not_exists(
                id=container_name,
                partition_key=PartitionKey(path=config['partition_key']),
                default_ttl=config.get('ttl', None)
            )
            container_clients[container_name] = container
            print(f"âœ… Container '{container_name}' ready")
        except Exception as e:
            print(f"âŒ Error creating container {container_name}: {e}")
    
    return database, container_clients

def seed_cosmos_data(container_clients):
    """Seed data into Cosmos DB containers"""
    print("ðŸ“¦ Seeding Cosmos DB data...")
    
    # Data file mappings (relative to challenge-0 directory)
    data_mappings = {
        'Machines': 'data/machines.json',
        'Thresholds': 'data/thresholds.json',
        'Telemetry': 'data/telemetry-samples.json',
        'KnowledgeBase': 'data/knowledge-base.json',
        'PartsInventory': 'data/parts-inventory.json',
        'Technicians': 'data/technicians.json',
        'WorkOrders': 'data/work-orders.json',
        'MaintenanceHistory': 'data/maintenance-history.json',
        'MaintenanceWindows': 'data/maintenance-windows.json'
    }
    
    for container_name, file_path in data_mappings.items():
        if container_name in container_clients:
            data = load_json_data(file_path)
            if data:
                container = container_clients[container_name]
                success_count = 0
                for item in data:
                    try:
                        # Ensure document has an id
                        if 'id' not in item:
                            print(f"âš ï¸ Item in {container_name} missing 'id' field")
                            continue
                        container.create_item(body=item)
                        success_count += 1
                    except Exception as e:
                        if "Conflict" not in str(e):  # Ignore conflicts (already exists)
                            print(f"âš ï¸ Error inserting item into {container_name}: {e}")
                print(f"âœ… Imported {success_count} items into {container_name}")

def main():
    """Main function to orchestrate the data seeding"""
    # Check required environment variables
    required_vars = ['COSMOS_ENDPOINT', 'COSMOS_KEY']
    missing_vars = [var for var in required_vars if not os.environ.get(var)]
    
    if missing_vars:
        print(f"âŒ Missing environment variables: {', '.join(missing_vars)}")
        return
    
    # Set up Cosmos DB
    database, container_clients = setup_cosmos_db()
    if container_clients:
        seed_cosmos_data(container_clients)
    
    print("âœ… Data seeding completed successfully!")

if __name__ == "__main__":
    main()
EOF

# Run the Python script
echo "ðŸ Running data seeding script..."
python3 seed_data.py

# Clean up
rm seed_data.py

echo "âœ… Seeding complete!"

# Upload kb-wiki markdown files to Azure Blob Storage
echo "ðŸš€ Uploading kb-wiki markdown files to Blob Storage..."

# Create Python script to upload markdown files from kb-wiki
cat > seed_blob_wiki.py << 'EOF'
import os
import glob
from azure.storage.blob import BlobServiceClient, ContentSettings

def get_blob_service_client_from_env():
    """Create BlobServiceClient using AZURE_STORAGE_CONNECTION_STRING only."""
    conn = os.environ.get('AZURE_STORAGE_CONNECTION_STRING')
    if not conn:
        raise RuntimeError("Missing AZURE_STORAGE_CONNECTION_STRING in environment.")
    return BlobServiceClient.from_connection_string(conn)

def upload_markdown_files(container_name: str, folder_path: str):
    service_client = get_blob_service_client_from_env()
    container_client = service_client.get_container_client(container_name)
    try:
        container_client.create_container()
        print(f"âœ… Created container '{container_name}'")
    except Exception as e:
        # Likely already exists; continue
        print(f"â„¹ï¸ Container '{container_name}' ready or exists: {e}")

    files = glob.glob(os.path.join(folder_path, '*.md'))
    if not files:
        print(f"âš ï¸ No markdown files found in {folder_path}")
        return

    content_settings = ContentSettings(content_type='text/markdown; charset=utf-8')
    uploaded = 0
    for fpath in files:
        blob_name = os.path.basename(fpath)
        try:
            with open(fpath, 'rb') as f:
                container_client.upload_blob(name=blob_name, data=f, overwrite=True, content_settings=content_settings)
            uploaded += 1
            print(f"âœ… Uploaded {blob_name}")
        except Exception as e:
            print(f"âŒ Failed to upload {blob_name}: {e}")

    print(f"âœ… Completed upload: {uploaded} file(s) to '{container_name}'")

def main():
    # Resolve container and folder (relative to challenge-0 directory)
    container_name = 'machine-wiki' 
    folder_path = os.path.join('data', 'kb-wiki')

    if not os.path.isdir(folder_path):
        raise RuntimeError(f"kb-wiki folder not found at {folder_path}")

    if not os.environ.get('AZURE_STORAGE_CONNECTION_STRING'):
        raise RuntimeError("Missing storage credentials. Set AZURE_STORAGE_CONNECTION_STRING in environment.")

    upload_markdown_files(container_name, folder_path)

if __name__ == '__main__':
    main()
EOF

echo "ðŸ Running kb-wiki upload script..."
python3 seed_blob_wiki.py

# Clean up uploader script
rm seed_blob_wiki.py

echo "âœ… Blob upload complete!"
